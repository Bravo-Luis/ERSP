{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain DeepTraffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wei Wang (ww8137@mail.ustc.edu.cn)\n",
    "#\n",
    "# This Source Code Form is subject to the terms of the Mozilla Public\n",
    "# License, v. 2.0. If a copy of the MPL was not distributed with this file, You\n",
    "# can obtain one at http://mozilla.org/MPL/2.0/.\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# start tensorflow interactiveSession\n",
    "import tensorflow.compat.v1 as tf  # load MNIST data\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from skexplain.utils import input_data\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "DATA_DIR = \"../res/dataset/DeepTraffic/2class/SessionAllLayers\"\n",
    "\n",
    "VALIDATION_DATA_DIR = \"../res/dataset/DeepTraffic/validation/2class/SessionAllLayers\"\n",
    "VALIDATION_64_DATA_DIR = \"../res/dataset/DeepTraffic/validation/2class-64/SessionAllLayers\" # altered dataset byte 23 === 101\n",
    "VALIDATION_128_DATA_DIR = \"../res/dataset/DeepTraffic/validation/2class-128/SessionAllLayers\" # altered dataset byte 23 === 101\n",
    "VALIDATION_32_64_DATA_DIR = \"../res/dataset/DeepTraffic/validation/2class-32-64/SessionAllLayers\" # altered dataset byte 23 === 101\n",
    "VALIDATION_43_47_49_DATA_DIR = \"../res/dataset/DeepTraffic/validation/2class-43-47-49/SessionAllLayers\" # altered dataset byte 23 === 101\n",
    "\n",
    "\n",
    "CLASS_NUM = 2\n",
    "TRAIN_ROUND = 20000\n",
    "\n",
    "\n",
    "folder = os.path.split(DATA_DIR)[1]\n",
    "dict_2class = {0: \"Novpn\", 1: \"Vpn\"}\n",
    "dict_6class_novpn = {\n",
    "    0: \"Chat\",\n",
    "    1: \"Email\",\n",
    "    2: \"File\",\n",
    "    3: \"P2p\",\n",
    "    4: \"Streaming\",\n",
    "    5: \"Voip\",\n",
    "}\n",
    "dict_6class_vpn = {\n",
    "    0: \"Vpn_Chat\",\n",
    "    1: \"Vpn_Email\",\n",
    "    2: \"Vpn_File\",\n",
    "    3: \"Vpn_P2p\",\n",
    "    4: \"Vpn_Streaming\",\n",
    "    5: \"Vpn_Voip\",\n",
    "}\n",
    "dict_12class = {\n",
    "    0: \"Chat\",\n",
    "    1: \"Email\",\n",
    "    2: \"File\",\n",
    "    3: \"P2p\",\n",
    "    4: \"Streaming\",\n",
    "    5: \"Voip\",\n",
    "    6: \"Vpn_Chat\",\n",
    "    7: \"Vpn_Email\",\n",
    "    8: \"Vpn_File\",\n",
    "    9: \"Vpn_P2p\",\n",
    "    10: \"Vpn_Streaming\",\n",
    "    11: \"Vpn_Voip\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_element_in_list(element, list_element):\n",
    "    try:\n",
    "        index_element = list_element.index(element)\n",
    "        return index_element\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# convolution\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# pooling\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 3, 1], strides=[1, 1, 3, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "class DeepTraffic:\n",
    "    def __init__(self):\n",
    "        self.sess = tf.InteractiveSession()\n",
    "\n",
    "        # Create the model\n",
    "        # placeholder\n",
    "        self.x = tf.placeholder(\"float\", [None, 784])\n",
    "        self.y_ = tf.placeholder(\"float\", [None, CLASS_NUM])\n",
    "\n",
    "        # first convolutinal layer\n",
    "        self.w_conv1 = weight_variable([1, 25, 1, 32])\n",
    "        self.b_conv1 = bias_variable([32])\n",
    "\n",
    "        self.x_image = tf.reshape(self.x, [-1, 1, 784, 1])\n",
    "\n",
    "        self.h_conv1 = tf.nn.relu(conv2d(self.x_image, self.w_conv1) + self.b_conv1)\n",
    "        self.h_pool1 = max_pool_2x2(self.h_conv1)\n",
    "\n",
    "        # second convolutional layer\n",
    "        self.w_conv2 = weight_variable([1, 25, 32, 64])\n",
    "        self.b_conv2 = bias_variable([64])\n",
    "\n",
    "        self.h_conv2 = tf.nn.relu(conv2d(self.h_pool1, self.w_conv2) + self.b_conv2)\n",
    "        self.h_pool2 = max_pool_2x2(self.h_conv2)\n",
    "\n",
    "        # densely connected layer\n",
    "        self.w_fc1 = weight_variable([1 * 88 * 64, 1024])\n",
    "        self.b_fc1 = bias_variable([1024])\n",
    "\n",
    "        self.h_pool2_flat = tf.reshape(self.h_pool2, [-1, 1 * 88 * 64])\n",
    "        self.h_fc1 = tf.nn.relu(tf.matmul(self.h_pool2_flat, self.w_fc1) + self.b_fc1)\n",
    "\n",
    "        # dropout\n",
    "        self.keep_prob = tf.placeholder(\"float\")\n",
    "        self.h_fc1_drop = tf.nn.dropout(self.h_fc1, self.keep_prob)\n",
    "\n",
    "        # readout layer\n",
    "        self.w_fc2 = weight_variable([1024, CLASS_NUM])\n",
    "        self.b_fc2 = bias_variable([CLASS_NUM])\n",
    "\n",
    "        # From Site1997:\n",
    "        # This would cause nan or 0 gradient if \"tf.matmul(h_fc1_drop, w_fc2) + b_fc2\" is all zero or nan,\n",
    "        # so when the training iteration is big enough, all weights could suddenly became 0.\n",
    "        # Use tf.nn.ax_cross_entropy_with_logits instead. It handles the extreme case safely.\n",
    "        self.y_conv = tf.nn.softmax(tf.matmul(self.h_fc1_drop, self.w_fc2) + self.b_fc2)\n",
    "\n",
    "        # y_conv = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=tf.matmul(h_fc1_drop, w_fc2) + b_fc2)\n",
    "\n",
    "        # define var&op of training&testing\n",
    "        self.actual_label = tf.argmax(self.y_, 1)\n",
    "        self.label, self.idx, self.count = tf.unique_with_counts(self.actual_label)\n",
    "        self.cross_entropy = -tf.reduce_sum(self.y_ * tf.log(self.y_conv))\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(1e-4).minimize(\n",
    "            self.cross_entropy\n",
    "        )\n",
    "        self.predict_label = tf.argmax(self.y_conv, 1)\n",
    "        self.label_p, self.dx_p, self.count_p = tf.unique_with_counts(\n",
    "            self.predict_label\n",
    "        )\n",
    "        self.correct_prediction = tf.equal(self.predict_label, self.actual_label)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, \"float\"))\n",
    "        self.correct_label = tf.boolean_mask(self.actual_label, self.correct_prediction)\n",
    "        self.label_c, self.idx_c, self.count_c = tf.unique_with_counts(\n",
    "            self.correct_label\n",
    "        )\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        # if model exists: restore it\n",
    "        # else: train a new model and save it\n",
    "        saver = tf.train.Saver()\n",
    "        model_name = \"model_\" + str(CLASS_NUM) + \"class_\" + folder\n",
    "        model = model_name + \"/\" + model_name + \".ckpt\"\n",
    "        print(model)\n",
    "        i = 0\n",
    "        if not os.path.exists(model + \".meta\"):\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            if not os.path.exists(model_name):\n",
    "                os.makedirs(model_name)\n",
    "\n",
    "            for i in range(TRAIN_ROUND + 1):\n",
    "                batch = dataset.next_batch(50)\n",
    "                # batch = mnist_train.shuffle(1204).batch(50).repeat(TRAIN_ROUND + 1).prefetch(10)\n",
    "                # for sample in tensorflow_datasets.as_numpy(batch):\n",
    "                # batch_images, batch_labels = sample[\"image\"].reshape(\n",
    "                # [50, 784]), tensorflow_datasets.as_numpy(tf.one_hot(sample[\"label\"], CLASS_NUM))\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    train_accuracy = self.accuracy.eval(\n",
    "                        feed_dict={\n",
    "                            self.x: batch[0],\n",
    "                            self.y_: batch[1],\n",
    "                            self.keep_prob: 1.0,\n",
    "                        }\n",
    "                    )\n",
    "                    s = \"step %d, train accuracy %g\" % (i, train_accuracy)\n",
    "                    print(s)\n",
    "                    # if i%2000 == 0:\n",
    "                    #     with open('out.txt','a') as f:\n",
    "                    #         f.write(s + \"\\n\")\n",
    "                self.train_step.run(\n",
    "                    feed_dict={self.x: batch[0], self.y_: batch[1], self.keep_prob: 0.5}\n",
    "                )\n",
    "                # i += 1\n",
    "\n",
    "            save_path = saver.save(self.sess, model)\n",
    "            print(\"Model saved in file:\", save_path)\n",
    "        else:\n",
    "            saver.restore(self.sess, model)\n",
    "            print(\"Model restored: \" + model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        params = [self.y_conv]\n",
    "        y = self.sess.run(\n",
    "            params,\n",
    "            {self.x: X, self.keep_prob: 1.0},\n",
    "        )\n",
    "\n",
    "        return np.array([np.argmax(test) for test in y[0]])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        params = [self.y_conv]\n",
    "        y = self.sess.run(\n",
    "            params,\n",
    "            {self.x: X, self.keep_prob: 1.0},\n",
    "        )\n",
    "        \n",
    "        return np.array(y[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTraffic Script Start\n",
      "Extracting ../res/dataset/DeepTraffic/2class/SessionAllLayers/train-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/2class/SessionAllLayers/train-labels-idx1-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/2class/SessionAllLayers/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/2class/SessionAllLayers/t10k-labels-idx1-ubyte.gz\n",
      "Initializing DeepTraffic\n",
      "WARNING:tensorflow:From /Users/asjacobs/Library/Caches/pypoetry/virtualenvs/scikit-explain-TZFnvs_5-py3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "model_2class_SessionAllLayers/model_2class_SessionAllLayers.ckpt\n",
      "INFO:tensorflow:Restoring parameters from model_2class_SessionAllLayers/model_2class_SessionAllLayers.ckpt\n",
      "Model restored: model_2class_SessionAllLayers/model_2class_SessionAllLayers.ckpt\n",
      "(30501, 784)\n",
      "(3945, 784)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Novpn      1.000     1.000     1.000      2692\n",
      "         Vpn      0.999     0.999     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DeepTraffic Script Start\")\n",
    "dataset = input_data.read_data_sets(DATA_DIR, one_hot=True, num_classes=CLASS_NUM)\n",
    "\n",
    "dict = {}\n",
    "# evaluate the model\n",
    "if CLASS_NUM == 12:\n",
    "    dict = dict_12class\n",
    "elif CLASS_NUM == 2:\n",
    "    dict = dict_2class\n",
    "elif CLASS_NUM == 6:\n",
    "    if folder.startswith(\"Novpn\"):\n",
    "        dict = dict_6class_novpn\n",
    "    elif folder.startswith(\"Vpn\"):\n",
    "        dict = dict_6class_vpn\n",
    "\n",
    "\n",
    "class_names = dict.values()  \n",
    "print(\"Initializing DeepTraffic\")\n",
    "deep_traffic = DeepTraffic()\n",
    "deep_traffic.fit(dataset.train)\n",
    "X_train = dataset.train.images\n",
    "y_train = np.array([np.argmax(i) for i in dataset.train.labels])\n",
    "X_test = dataset.test.images\n",
    "y_test = np.array([np.argmax(i) for i in dataset.test.labels])\n",
    "y_pred = deep_traffic.predict(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\n",
    "    \"{}\".format(\n",
    "        classification_report(y_test, y_pred, digits=3, target_names=class_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTraffic Validation Start\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class/SessionAllLayers/train-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class/SessionAllLayers/train-labels-idx1-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class/SessionAllLayers/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class/SessionAllLayers/t10k-labels-idx1-ubyte.gz\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Novpn      0.927     1.000     0.962      1859\n",
      "         Vpn      1.000     0.902     0.948      1497\n",
      "\n",
      "    accuracy                          0.956      3356\n",
      "   macro avg      0.963     0.951     0.955      3356\n",
      "weighted avg      0.959     0.956     0.956      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DeepTraffic Validation Start\")\n",
    "validation_dataset = input_data.read_data_sets(VALIDATION_DATA_DIR, one_hot=True, num_classes=CLASS_NUM)\n",
    "\n",
    "X_validation = validation_dataset.test.images\n",
    "y_validation = np.array([np.argmax(i) for i in validation_dataset.test.labels])\n",
    "y_val_pred = deep_traffic.predict(X_validation)\n",
    "\n",
    "print(\n",
    "    \"{}\".format(\n",
    "        classification_report(y_validation, y_val_pred, digits=3, target_names=class_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTraffic Validation Start\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-64/SessionAllLayers/train-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-64/SessionAllLayers/train-labels-idx1-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-64/SessionAllLayers/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-64/SessionAllLayers/t10k-labels-idx1-ubyte.gz\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Novpn      0.695     1.000     0.820      1859\n",
      "         Vpn      1.000     0.456     0.626      1497\n",
      "\n",
      "    accuracy                          0.757      3356\n",
      "   macro avg      0.848     0.728     0.723      3356\n",
      "weighted avg      0.831     0.757     0.734      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DeepTraffic Validation Start\")\n",
    "alt_64_dataset = input_data.read_data_sets(VALIDATION_64_DATA_DIR, one_hot=True, num_classes=CLASS_NUM)\n",
    "\n",
    "X_validation_alt_64 = alt_64_dataset.test.images\n",
    "y_validation_alt_64 = np.array([np.argmax(i) for i in alt_64_dataset.test.labels])\n",
    "y_val_alt_64_pred = deep_traffic.predict(X_validation_alt_64)\n",
    "\n",
    "print(\n",
    "    \"{}\".format(\n",
    "        classification_report(y_validation_alt_64, y_val_alt_64_pred, digits=3, target_names=class_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTraffic Validation Start\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-128/SessionAllLayers/train-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-128/SessionAllLayers/train-labels-idx1-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-128/SessionAllLayers/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-128/SessionAllLayers/t10k-labels-idx1-ubyte.gz\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Novpn      0.555     1.000     0.714      1859\n",
      "         Vpn      1.000     0.003     0.007      1497\n",
      "\n",
      "    accuracy                          0.555      3356\n",
      "   macro avg      0.777     0.502     0.360      3356\n",
      "weighted avg      0.753     0.555     0.398      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DeepTraffic Validation Start\")\n",
    "alt_128_dataset = input_data.read_data_sets(VALIDATION_128_DATA_DIR, one_hot=True, num_classes=CLASS_NUM)\n",
    "\n",
    "X_validation_alt_128 = alt_128_dataset.test.images\n",
    "y_validation_alt_128 = np.array([np.argmax(i) for i in alt_128_dataset.test.labels])\n",
    "y_val_alt_128_pred = deep_traffic.predict(X_validation_alt_128)\n",
    "\n",
    "print(\n",
    "    \"{}\".format(\n",
    "        classification_report(y_validation_alt_128, y_val_alt_128_pred, digits=3, target_names=class_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTraffic Validation Start\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-32-64/SessionAllLayers/train-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-32-64/SessionAllLayers/train-labels-idx1-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-32-64/SessionAllLayers/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-32-64/SessionAllLayers/t10k-labels-idx1-ubyte.gz\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Novpn      0.799     1.000     0.888      1859\n",
      "         Vpn      1.000     0.688     0.815      1497\n",
      "\n",
      "    accuracy                          0.861      3356\n",
      "   macro avg      0.900     0.844     0.852      3356\n",
      "weighted avg      0.889     0.861     0.856      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DeepTraffic Validation Start\")\n",
    "alt_32_64_dataset = input_data.read_data_sets(VALIDATION_32_64_DATA_DIR, one_hot=True, num_classes=CLASS_NUM)\n",
    "\n",
    "X_validation_alt_32_64 = alt_32_64_dataset.test.images\n",
    "y_validation_alt_32_64 = np.array([np.argmax(i) for i in alt_32_64_dataset.test.labels])\n",
    "y_val_alt_32_64_pred = deep_traffic.predict(X_validation_alt_32_64)\n",
    "\n",
    "print(\n",
    "    \"{}\".format(\n",
    "        classification_report(y_validation_alt_32_64, y_val_alt_32_64_pred, digits=3, target_names=class_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepTraffic Validation Start\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-43-47-49/SessionAllLayers/train-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-43-47-49/SessionAllLayers/train-labels-idx1-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-43-47-49/SessionAllLayers/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../res/dataset/DeepTraffic/validation/2class-43-47-49/SessionAllLayers/t10k-labels-idx1-ubyte.gz\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Novpn      0.926     1.000     0.961      1859\n",
      "         Vpn      1.000     0.900     0.948      1497\n",
      "\n",
      "    accuracy                          0.956      3356\n",
      "   macro avg      0.963     0.950     0.955      3356\n",
      "weighted avg      0.959     0.956     0.955      3356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"DeepTraffic Validation Start\")\n",
    "alt_43_47_49_dataset = input_data.read_data_sets(VALIDATION_43_47_49_DATA_DIR, one_hot=True, num_classes=CLASS_NUM)\n",
    "\n",
    "X_validation_alt_43_47_49 = alt_43_47_49_dataset.test.images\n",
    "y_validation_alt_43_47_49 = np.array([np.argmax(i) for i in alt_43_47_49_dataset.test.labels])\n",
    "y_val_alt_43_47_49_pred = deep_traffic.predict(X_validation_alt_43_47_49)\n",
    "\n",
    "print(\n",
    "    \"{}\".format(\n",
    "        classification_report(y_validation_alt_43_47_49, y_val_alt_43_47_49_pred, digits=3, target_names=class_names)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/5733203304/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/5733203304/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "from interpret.blackbox import LimeTabular\n",
    "\n",
    "# Blackbox explainers need a predict function, and optionally a dataset\n",
    "lime = LimeTabular(predict_fn=deep_traffic.predict_proba, data=X_train, random_state=1)\n",
    "\n",
    "# Pick the instances to explain, optionally pass in labels if you have them\n",
    "# test_cases = [int(n) for n in y_test]\n",
    "\n",
    "lime_local = lime.explain_local([X_test[5]], [y_test[5]])\n",
    "print(y_test[5])\n",
    "\n",
    "show(lime_local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/5733201960/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/5733201960/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "lime_local = lime.explain_local([X_test[0]], [y_test[0]])\n",
    "print(y_test[0])\n",
    "\n",
    "show(lime_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_traffic.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-29 17:53:16,954 - INFO - Using Classification Dagger algorithm...\n",
      "2021-06-29 17:53:48,681 - INFO - ########## Explanation validation ##########\n",
      "2021-06-29 17:53:48,682 - INFO - Model explanation 0 local fidelity: 1.0\n",
      "2021-06-29 17:53:48,685 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:48,694 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:48,695 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:48,702 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:49,099 - INFO - Model explanation 2 local fidelity: 1.0\n",
      "2021-06-29 17:53:49,105 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:49,112 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:49,113 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:49,120 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:49,454 - INFO - Model explanation 3 local fidelity: 1.0\n",
      "2021-06-29 17:53:49,459 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:49,467 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:49,468 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:49,475 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:49,809 - INFO - Model explanation 4 local fidelity: 1.0\n",
      "2021-06-29 17:53:49,816 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:49,823 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     1.000      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     1.000     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:49,824 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:49,830 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:50,162 - INFO - Model explanation 6 local fidelity: 1.0\n",
      "2021-06-29 17:53:50,167 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:50,175 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     1.000      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     1.000     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:50,176 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:50,182 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:50,513 - INFO - Model explanation 7 local fidelity: 1.0\n",
      "2021-06-29 17:53:50,519 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:50,527 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     1.000      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     1.000     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:50,528 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:50,535 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:50,873 - INFO - Model explanation 9 local fidelity: 1.0\n",
      "2021-06-29 17:53:50,879 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:50,887 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:50,888 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:50,896 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:51,240 - INFO - Model explanation 16 local fidelity: 1.0\n",
      "2021-06-29 17:53:51,246 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:51,253 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:51,254 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:51,261 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:51,591 - INFO - Model explanation 18 local fidelity: 1.0\n",
      "2021-06-29 17:53:51,598 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:51,605 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-29 17:53:51,606 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:51,614 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.997     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.998     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:51,949 - INFO - Model explanation 19 local fidelity: 1.0\n",
      "2021-06-29 17:53:51,955 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:51,963 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     1.000      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     1.000     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:51,964 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:51,972 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:52,303 - INFO - Model explanation 21 local fidelity: 1.0\n",
      "2021-06-29 17:53:52,308 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:52,316 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     1.000      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     1.000     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:52,318 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:52,326 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:52,658 - INFO - Model explanation 28 local fidelity: 1.0\n",
      "2021-06-29 17:53:52,663 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:52,671 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:52,672 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:52,679 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.997     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.998     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:53,012 - INFO - Model explanation 33 local fidelity: 1.0\n",
      "2021-06-29 17:53:53,017 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:53,025 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:53,026 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:53,032 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:53,369 - INFO - Model explanation 34 local fidelity: 1.0\n",
      "2021-06-29 17:53:53,376 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:53,383 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:53,384 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:53,392 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:53,726 - INFO - Model explanation 35 local fidelity: 1.0\n",
      "2021-06-29 17:53:53,732 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:53,739 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     1.000      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     1.000     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:53,740 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:53,747 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:54,087 - INFO - Model explanation 40 local fidelity: 1.0\n",
      "2021-06-29 17:53:54,093 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:54,101 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:54,102 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:54,109 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:54,443 - INFO - Model explanation 41 local fidelity: 1.0\n",
      "2021-06-29 17:53:54,449 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:54,457 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.999     1.000     1.000      2692\n",
      "           1      1.000     0.998     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      1.000     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:54,458 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:54,466 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.999     1.000     0.999      2692\n",
      "           1      0.999     0.998     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:54,798 - INFO - Model explanation 42 local fidelity: 1.0\n",
      "2021-06-29 17:53:54,804 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:54,812 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-29 17:53:54,814 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:54,822 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000      2692\n",
      "           1      1.000     0.999     1.000      1253\n",
      "\n",
      "    accuracy                          1.000      3945\n",
      "   macro avg      1.000     1.000     1.000      3945\n",
      "weighted avg      1.000     1.000     1.000      3945\n",
      "\n",
      "2021-06-29 17:53:55,157 - INFO - Model explanation 44 local fidelity: 1.0\n",
      "2021-06-29 17:53:55,163 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:55,170 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:55,171 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:55,178 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.997     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.998     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:55,514 - INFO - Model explanation 49 local fidelity: 1.0\n",
      "2021-06-29 17:53:55,520 - INFO - Model explanation classification report:\n",
      "2021-06-29 17:53:55,527 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.998     1.000     0.999      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.999     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n",
      "2021-06-29 17:53:55,528 - INFO - Model explanation global fidelity report:\n",
      "2021-06-29 17:53:55,536 - INFO - \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.999     0.999      2692\n",
      "           1      0.997     0.999     0.998      1253\n",
      "\n",
      "    accuracy                          0.999      3945\n",
      "   macro avg      0.998     0.999     0.999      3945\n",
      "weighted avg      0.999     0.999     0.999      3945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "import rootpath\n",
    "\n",
    "from skexplain.imitation import ClassificationDagger\n",
    "from skexplain.utils import log\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, f1_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "logger = log.Logger(\"{}/res/log/{}/dagger_test.log\".format(rootpath.detect(), 'DeepTraffic'))\n",
    "\n",
    "logger.log(\"Using Classification Dagger algorithm...\")\n",
    "dagger = ClassificationDagger(expert=deep_traffic, logger=logger)\n",
    "\n",
    "dagger.fit(X_train, y_train, max_iter=50, max_leaf_nodes=None,\n",
    "           num_samples=5000, ccp_alpha=0.0002)\n",
    "\n",
    "logger.log(\"#\" * 10, \"Explanation validation\", \"#\" * 10)\n",
    "(_, max_reward, _) = dagger.explain()\n",
    "\n",
    "students = dagger.get_students()\n",
    "all_explanations = [student for student in students if student[1] == max_reward]\n",
    "\n",
    "for (dt, reward, idx) in all_explanations:\n",
    "    logger.log(\"Model explanation {} local fidelity: {}\".format(idx, reward))\n",
    "    dt_y_pred = dt.predict(X_test)\n",
    "\n",
    "    logger.log(\"Model explanation classification report:\")\n",
    "    logger.log(\"\\n{}\".format(classification_report(y_test, dt_y_pred, digits=3)))\n",
    "\n",
    "    logger.log(\"Model explanation global fidelity report:\")\n",
    "    logger.log(\"\\n{}\".format(classification_report(y_pred, dt_y_pred, digits=3)))\n",
    "    \n",
    "    dot_data = tree.export_graphviz(dt,\n",
    "                                class_names=list(class_names),\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(\"{}/res/img/{}/{}/dt_{}_{}\".format(rootpath.detect(),\n",
    "                                                        \"DeepTraffic\",\n",
    "                                                        \"dagger\",\n",
    "                                                        dt.get_n_leaves(), \n",
    "                                                        idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.0 (20210316.0004)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"503pt\" height=\"304pt\"\n",
       " viewBox=\"0.00 0.00 503.00 304.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-300 499,-300 499,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f1bb95\" stroke=\"black\" d=\"M305,-296C305,-296 189,-296 189,-296 183,-296 177,-290 177,-284 177,-284 177,-230 177,-230 177,-224 183,-218 189,-218 189,-218 305,-218 305,-218 311,-218 317,-224 317,-230 317,-230 317,-284 317,-284 317,-290 311,-296 305,-296\"/>\n",
       "<text text-anchor=\"start\" x=\"210.5\" y=\"-281.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X</text>\n",
       "<text text-anchor=\"start\" x=\"220.5\" y=\"-281.8\" font-family=\"Helvetica,sans-Serif\" baseline-shift=\"sub\" font-size=\"14.00\">49</text>\n",
       "<text text-anchor=\"start\" x=\"234.5\" y=\"-281.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> ≤ 0.069</text>\n",
       "<text text-anchor=\"start\" x=\"211.5\" y=\"-267.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.433</text>\n",
       "<text text-anchor=\"start\" x=\"194.5\" y=\"-253.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14000</text>\n",
       "<text text-anchor=\"start\" x=\"185\" y=\"-239.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9563, 4437]</text>\n",
       "<text text-anchor=\"start\" x=\"204\" y=\"-225.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Novpn</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M224.5,-182C224.5,-182 131.5,-182 131.5,-182 125.5,-182 119.5,-176 119.5,-170 119.5,-170 119.5,-116 119.5,-116 119.5,-110 125.5,-104 131.5,-104 131.5,-104 224.5,-104 224.5,-104 230.5,-104 236.5,-110 236.5,-116 236.5,-116 236.5,-170 236.5,-170 236.5,-176 230.5,-182 224.5,-182\"/>\n",
       "<text text-anchor=\"start\" x=\"141.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X</text>\n",
       "<text text-anchor=\"start\" x=\"151.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" baseline-shift=\"sub\" font-size=\"14.00\">43</text>\n",
       "<text text-anchor=\"start\" x=\"165.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> ≤ 0.006</text>\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.003</text>\n",
       "<text text-anchor=\"start\" x=\"129.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4432</text>\n",
       "<text text-anchor=\"start\" x=\"127.5\" y=\"-125.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 4426]</text>\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Vpn</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.45,-217.77C218.06,-209.03 212.28,-199.64 206.71,-190.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"209.67,-188.74 201.45,-182.06 203.71,-192.41 209.67,-188.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"195.67\" y=\"-202.68\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M367.5,-182C367.5,-182 266.5,-182 266.5,-182 260.5,-182 254.5,-176 254.5,-170 254.5,-170 254.5,-116 254.5,-116 254.5,-110 260.5,-104 266.5,-104 266.5,-104 367.5,-104 367.5,-104 373.5,-104 379.5,-110 379.5,-116 379.5,-116 379.5,-170 379.5,-170 379.5,-176 373.5,-182 367.5,-182\"/>\n",
       "<text text-anchor=\"start\" x=\"280.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">X</text>\n",
       "<text text-anchor=\"start\" x=\"290.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" baseline-shift=\"sub\" font-size=\"14.00\">47</text>\n",
       "<text text-anchor=\"start\" x=\"304.5\" y=\"-167.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\"> ≤ 0.988</text>\n",
       "<text text-anchor=\"start\" x=\"281.5\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.002</text>\n",
       "<text text-anchor=\"start\" x=\"268.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9568</text>\n",
       "<text text-anchor=\"start\" x=\"262.5\" y=\"-125.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9557, 11]</text>\n",
       "<text text-anchor=\"start\" x=\"274\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Novpn</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.89,-217.77C276.36,-209.03 282.22,-199.64 287.88,-190.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.88,-192.39 293.21,-182.06 284.95,-188.68 290.88,-192.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"298.83\" y=\"-202.72\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M90,-68C90,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 90,0 90,0 96,0 102,-6 102,-12 102,-12 102,-56 102,-56 102,-62 96,-68 90,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"23\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"13.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"11.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Novpn</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M132.87,-103.97C121.63,-94.51 109.55,-84.33 98.22,-74.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.41,-72.05 90.51,-68.28 95.9,-77.4 100.41,-72.05\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M225.5,-68C225.5,-68 132.5,-68 132.5,-68 126.5,-68 120.5,-62 120.5,-56 120.5,-56 120.5,-12 120.5,-12 120.5,-6 126.5,0 132.5,0 132.5,0 225.5,0 225.5,0 231.5,0 237.5,-6 237.5,-12 237.5,-12 237.5,-56 237.5,-56 237.5,-62 231.5,-68 225.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"130.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4426</text>\n",
       "<text text-anchor=\"start\" x=\"128.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4426]</text>\n",
       "<text text-anchor=\"start\" x=\"143.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Vpn</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.36,-103.97C178.43,-95.69 178.52,-86.86 178.59,-78.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.1,-78.32 178.69,-68.28 175.1,-78.25 182.1,-78.32\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M362.5,-68C362.5,-68 269.5,-68 269.5,-68 263.5,-68 257.5,-62 257.5,-56 257.5,-56 257.5,-12 257.5,-12 257.5,-6 263.5,0 269.5,0 269.5,0 362.5,0 362.5,0 368.5,0 374.5,-6 374.5,-12 374.5,-12 374.5,-56 374.5,-56 374.5,-62 368.5,-68 362.5,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"288\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"267.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9557</text>\n",
       "<text text-anchor=\"start\" x=\"265.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9557, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"273\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Novpn</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M316.64,-103.97C316.57,-95.69 316.48,-86.86 316.41,-78.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"319.9,-78.25 316.31,-68.28 312.9,-78.32 319.9,-78.25\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M483,-68C483,-68 405,-68 405,-68 399,-68 393,-62 393,-56 393,-56 393,-12 393,-12 393,-6 399,0 405,0 405,0 483,0 483,0 489,0 495,-6 495,-12 495,-12 495,-56 495,-56 495,-62 489,-68 483,-68\"/>\n",
       "<text text-anchor=\"start\" x=\"416\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"403\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n",
       "<text text-anchor=\"start\" x=\"401\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 11]</text>\n",
       "<text text-anchor=\"start\" x=\"408.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Vpn</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M362.13,-103.97C373.37,-94.51 385.45,-84.33 396.78,-74.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"399.1,-77.4 404.49,-68.28 394.59,-72.05 399.1,-77.4\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x155bc77f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "dot_data = tree.export_graphviz(dt,\n",
    "                                class_names=list(class_names),\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"{}/res/img/{}/{}/dt_{}\".format(rootpath.detect(),\n",
    "                                                    \"DeepTraffic\",\n",
    "                                                    \"dagger\",\n",
    "                                                    dt.get_n_leaves()))\n",
    "\n",
    "display(graph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
